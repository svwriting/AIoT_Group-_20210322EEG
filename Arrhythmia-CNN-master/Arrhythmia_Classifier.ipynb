{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Arrhythmia_Classifier.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"jfFimB1yNBsI","executionInfo":{"status":"ok","timestamp":1616590770814,"user_tz":-480,"elapsed":802,"user":{"displayName":"old time","photoUrl":"","userId":"08992271775329336379"}}},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWAz-ZKvvoG1","executionInfo":{"status":"ok","timestamp":1616590771671,"user_tz":-480,"elapsed":1651,"user":{"displayName":"old time","photoUrl":"","userId":"08992271775329336379"}},"outputId":"b788e4bb-49e4-4729-9420-a56e04bfac7f"},"source":["%cd /content/drive/MyDrive/Arrhythmia-CNN-master\n","%ls"],"execution_count":62,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Arrhythmia-CNN-master\n"," Arrhythmia_Classifier.ipynb       'Create Arrhythmia Dataset.py'   \u001b[0m\u001b[01;34msave_model\u001b[0m/\n"," Arrhythmia_Classifier.py           \u001b[01;34mdata\u001b[0m/\n","'Create Arrhythmia Dataset.ipynb'   README.md\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DQe4oL9OwB9y","executionInfo":{"status":"ok","timestamp":1616590771672,"user_tz":-480,"elapsed":1647,"user":{"displayName":"old time","photoUrl":"","userId":"08992271775329336379"}}},"source":["# !pip install "],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"O8rMuPNOvnoC","executionInfo":{"status":"ok","timestamp":1616590771672,"user_tz":-480,"elapsed":1645,"user":{"displayName":"old time","photoUrl":"","userId":"08992271775329336379"}}},"source":["from __future__ import print_function\n","import torch\n","import torch.utils.data\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","from torch import nn, optim\n","from torch.utils.data.dataset import Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhd4wGF0gnJM","executionInfo":{"status":"ok","timestamp":1616590771673,"user_tz":-480,"elapsed":1643,"user":{"displayName":"old time","photoUrl":"","userId":"08992271775329336379"}}},"source":["\n","\n","is_cuda = False\n","# num_epochs = 100\n","num_epochs = 30\n","batch_size = 10\n","torch.manual_seed(46)\n","log_interval = 10\n","in_channels_ = 1\n","num_segments_in_record = 100\n","segment_len = 3600\n","num_records = 48\n","num_classes = 16\n","allow_label_leakage = True\n","\n","device = torch.device(\"cuda:0\" if is_cuda else \"cpu\")\n","# train_ids, test_ids = train_test_split(np.arange(index_set), train_size=.8, random_state=46)\n","# scaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kw5I8RsjvXRW","executionInfo":{"status":"ok","timestamp":1616590771673,"user_tz":-480,"elapsed":1641,"user":{"displayName":"old time","photoUrl":"","userId":"08992271775329336379"}}},"source":["\n","class CustomDatasetFromCSV(Dataset):\n","    def __init__(self, data_path, transforms_=None):\n","        self.df = pd.read_pickle(data_path)\n","        self.transforms = transforms_\n","\n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        signal = row['signal']\n","        target = row['target']\n","        if self.transforms is not None:\n","            signal = self.transforms(signal)\n","        signal = signal.reshape(1, signal.shape[0])\n","        return signal, target\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZJhvEu0Lvdnw","executionInfo":{"status":"ok","timestamp":1616590771673,"user_tz":-480,"elapsed":1638,"user":{"displayName":"old time","photoUrl":"","userId":"08992271775329336379"}}},"source":["\n","class Flatten(torch.nn.Module):\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","        return x.view(batch_size, -1)\n","\n","def basic_layer(in_channels, out_channels, kernel_size, batch_norm=False, max_pool=True, conv_stride=1, padding=0\n","                , pool_stride=2, pool_size=2):\n","    layer = nn.Sequential(\n","        nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=conv_stride,\n","                  padding=padding),\n","        nn.ReLU())\n","    if batch_norm:\n","        layer = nn.Sequential(\n","            layer,\n","            nn.BatchNorm1d(num_features=out_channels))\n","    if max_pool:\n","        layer = nn.Sequential(\n","            layer,\n","            nn.MaxPool1d(kernel_size=pool_size, stride=pool_stride))\n","\n","    return layer\n","\n","class arrhythmia_classifier(nn.Module):\n","    def __init__(self, in_channels=in_channels_):\n","        super(arrhythmia_classifier, self).__init__()\n","        self.cnn = nn.Sequential(\n","            basic_layer(in_channels=in_channels, out_channels=128, kernel_size=50, batch_norm=True, max_pool=True,\n","                        conv_stride=3, pool_stride=3),\n","            basic_layer(in_channels=128, out_channels=32, kernel_size=7, batch_norm=True, max_pool=True,\n","                        conv_stride=1, pool_stride=2),\n","            basic_layer(in_channels=32, out_channels=32, kernel_size=10, batch_norm=False, max_pool=False,\n","                        conv_stride=1),\n","            basic_layer(in_channels=32, out_channels=128, kernel_size=5, batch_norm=False, max_pool=True,\n","                        conv_stride=2, pool_stride=2),\n","            basic_layer(in_channels=128, out_channels=256, kernel_size=15, batch_norm=False, max_pool=True,\n","                        conv_stride=1, pool_stride=2),\n","            basic_layer(in_channels=256, out_channels=512, kernel_size=5, batch_norm=False, max_pool=False,\n","                        conv_stride=1),\n","            basic_layer(in_channels=512, out_channels=128, kernel_size=3, batch_norm=False, max_pool=False,\n","                        conv_stride=1),\n","            Flatten(),\n","            nn.Linear(in_features=1152, out_features=512),\n","            nn.ReLU(),\n","            nn.Dropout(p=.1),\n","            nn.Linear(in_features=512, out_features=num_classes),\n","            nn.Softmax()\n","        )\n","\n","    def forward(self, x, ex_features=None):\n","        return self.cnn(x)\n","\n","def calc_next_len_conv1d(current_len=112500, kernel_size=16, stride=8, padding=0, dilation=1):\n","    return int(np.floor((current_len + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1))\n"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXC-V5F-vZ_l","executionInfo":{"status":"ok","timestamp":1616590771674,"user_tz":-480,"elapsed":1637,"user":{"displayName":"old time","photoUrl":"","userId":"08992271775329336379"}}},"source":["\n","model = arrhythmia_classifier().to(device).double()\n","# lr = 0.0003 # learning rate\n","# lr = 3e-1 # learning rate\n","lr = 3e-2\n","# lr = 1e-3\n","# lr = 3e-4\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-6)\n","criterion = nn.NLLLoss()\n"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvJ6e-kkvjQQ","executionInfo":{"status":"ok","timestamp":1616590771674,"user_tz":-480,"elapsed":1635,"user":{"displayName":"old time","photoUrl":"","userId":"08992271775329336379"}}},"source":["\n","def train(epoch,train_loader):\n","    model.train()\n","    train_loss = 0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                       100. * batch_idx / len(train_loader),\n","                       loss.item() / len(data)))\n","\n","    print('====> Epoch: {} Average loss: {:.4f}'.format(\n","        epoch, train_loss / len(train_loader.dataset)))\n","    # import datetime\n","    # dt_=datetime.datetime.today().strftime(\"%Y%m%d-%H%M%S\")\n","    dt_=epoch\n","    torch.save(model,f'save_model/{dt_}.pt')\n","    \n","def test(epoch,test_loader):\n","    model.eval()\n","    test_loss = 0\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(test_loader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            test_loss += loss.item()\n","\n","            if batch_idx == 0:\n","                n = min(data.size(0), 4)\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('====> Test set loss: {:.5f}'.format(test_loss))\n","    print(f'Learning rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n","\n","def testModel(modelpath_,test_datasets_path,test_loader):\n","    # model = arrhythmia_classifier().to(device).double()\n","    # model.load_state_dict(torch.load(modelpath_))\n","    model=torch.load(modelpath_)\n","    model.eval()\n","    test_loss = 0\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(test_loader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            test_loss += loss.item()\n","\n","            if batch_idx == 0:\n","                n = min(data.size(0), 4)\n","\n","    test_loss /= len(test_loader.dataset)\n","    \n","    print(f'MODEL：[{modelpath_}]\\tTESTDATA：[{test_datasets_path}]')\n","    print('====> Test set loss: {:.5f}'.format(test_loss))\n","    print(f'Learning rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n","    return (modelpath_,test_loss)\n","\n","\n","\n"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"q7iYSFUxvlSY"},"source":["\n","# ./data/Arrhythmia_dataset_yystest.pkl\n","# ./data/Arrhythmia_dataset_yystest_noseed1.pkl\n","# ./data/Arrhythmia_dataset_yystest_noseed2.pkl\n","# ./data/Arrhythmia_dataset_yystest_noseed3.pkl\n","# ./data/Arrhythmia_dataset_yystest_noseed4.pkl\n","# ./data/Arrhythmia_dataset_yystest_noseed5.pkl\n","\n","# train_dataset = CustomDatasetFromCSV('./data/Arrhythmia_dataset.pkl')\n","train_dataset = CustomDatasetFromCSV('./data/Arrhythmia_dataset.pkl')\n","test_dataset = CustomDatasetFromCSV('./data/Arrhythmia_dataset_yystest.pkl')\n","\n","# test_dataset = CustomDatasetFromCSV('./data/Arrhythmia_dataset.pkl')\n","test_datasets_path=[\n","    \"./data/Arrhythmia_dataset_yystest_noseed1.pkl\",\n","    \"./data/Arrhythmia_dataset_yystest_noseed2.pkl\",\n","    \"./data/Arrhythmia_dataset_yystest_noseed3.pkl\",\n","    \"./data/Arrhythmia_dataset_yystest_noseed4.pkl\",\n","    \"./data/Arrhythmia_dataset_yystest_noseed5.pkl\",\n","]\n","\n","if __name__ == \"__main__\":    \n","    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n","    GANKnum_of_iteration = len(train_dataset) // batch_size\n","\n","    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    for epoch in range(1, num_epochs + 1):\n","        train(epoch,train_loader)\n","        test(epoch,test_loader)\n","    \n","    # modellist_=os.listdir(\"save_model\")\n","    # modelresults_={}\n","    # for test_dataset_path in test_datasets_path:\n","    #     test_dataset = CustomDatasetFromCSV(test_dataset_path)\n","    #     test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","    #     for modelpath_ in modellist_:\n","    #         result_=testModel(f'save_model/{modelpath_}',test_dataset_path,test_loader)\n","    #         if result_[0] not in modelresults_.keys():\n","    #           modelresults_[result_[0]]=[]\n","    #         modelresults_[result_[0]].append(result_[1])\n","    # for modelname_ in modelresults_:\n","    #     print(modelname_,end='\\t')\n","    #     for n_ in modelresults_[modelname_]:\n","    #         print(n_,end='\\t')\n","    #     print(sum(modelresults_[modelname_]))\n"],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Arrhythmia_Classifier_O.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QLZ02hKoc0Ec","executionInfo":{"status":"ok","timestamp":1616626558066,"user_tz":-480,"elapsed":19629,"user":{"displayName":"old time","photoUrl":"","userId":"08992271775329336379"}},"outputId":"dc7e0ca8-b298-4f4f-d1e6-f0a1d9d91f7c"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2kw30XXCctDz"},"source":["from __future__ import print_function\n","import torch\n","import torch.utils.data\n","import numpy as np\n","import pandas as pd\n","\n","from torch import nn, optim\n","from torch.utils.data.dataset import Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","is_cuda = False\n","num_epochs = 100\n","batch_size = 10\n","torch.manual_seed(46)\n","log_interval = 10\n","in_channels_ = 1\n","num_segments_in_record = 100\n","segment_len = 3600\n","num_records = 48\n","num_classes = 16\n","allow_label_leakage = True\n","\n","device = torch.device(\"cuda:2\" if is_cuda else \"cpu\")\n","# train_ids, test_ids = train_test_split(np.arange(index_set), train_size=.8, random_state=46)\n","# scaler = MinMaxScaler(feature_range=(0, 1), copy=False)\n","\n","\n","class CustomDatasetFromCSV(Dataset):\n","    def __init__(self, data_path, transforms_=None):\n","        self.df = pd.read_pickle(data_path)\n","        self.transforms = transforms_\n","\n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        signal = row['signal']\n","        target = row['target']\n","        if self.transforms is not None:\n","            signal = self.transforms(signal)\n","        signal = signal.reshape(1, signal.shape[0])\n","        return signal, target\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","\n","train_dataset = CustomDatasetFromCSV('/content/drive/MyDrive/Arrhythmia-CNN-master/data/Arrhythmia_dataset.pkl')\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n","test_dataset = CustomDatasetFromCSV('/content/drive/MyDrive/Arrhythmia-CNN-master/data/Arrhythmia_dataset.pkl')\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","\n","\n","class Flatten(torch.nn.Module):\n","    def forward(self, x):\n","        batch_size = x.shape[0]\n","        return x.view(batch_size, -1)\n","\n","\n","def basic_layer(in_channels, out_channels, kernel_size, batch_norm=False, max_pool=True, conv_stride=1, padding=0\n","                , pool_stride=2, pool_size=2):\n","    layer = nn.Sequential(\n","        nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=conv_stride,\n","                  padding=padding),\n","        nn.ReLU())\n","    if batch_norm:\n","        layer = nn.Sequential(\n","            layer,\n","            nn.BatchNorm1d(num_features=out_channels))\n","    if max_pool:\n","        layer = nn.Sequential(\n","            layer,\n","            nn.MaxPool1d(kernel_size=pool_size, stride=pool_stride))\n","\n","    return layer\n","\n","\n","class arrhythmia_classifier(nn.Module):\n","    def __init__(self, in_channels=in_channels_):\n","        super(arrhythmia_classifier, self).__init__()\n","        self.cnn = nn.Sequential(\n","            basic_layer(in_channels=in_channels, out_channels=128, kernel_size=50, batch_norm=True, max_pool=True,\n","                        conv_stride=3, pool_stride=3),\n","            basic_layer(in_channels=128, out_channels=32, kernel_size=7, batch_norm=True, max_pool=True,\n","                        conv_stride=1, pool_stride=2),\n","            basic_layer(in_channels=32, out_channels=32, kernel_size=10, batch_norm=False, max_pool=False,\n","                        conv_stride=1),\n","            basic_layer(in_channels=32, out_channels=128, kernel_size=5, batch_norm=False, max_pool=True,\n","                        conv_stride=2, pool_stride=2),\n","            basic_layer(in_channels=128, out_channels=256, kernel_size=15, batch_norm=False, max_pool=True,\n","                        conv_stride=1, pool_stride=2),\n","            basic_layer(in_channels=256, out_channels=512, kernel_size=5, batch_norm=False, max_pool=False,\n","                        conv_stride=1),\n","            basic_layer(in_channels=512, out_channels=128, kernel_size=3, batch_norm=False, max_pool=False,\n","                        conv_stride=1),\n","            Flatten(),\n","            nn.Linear(in_features=1152, out_features=512),\n","            nn.ReLU(),\n","            nn.Dropout(p=.1),\n","            nn.Linear(in_features=512, out_features=num_classes),\n","            nn.Softmax()\n","        )\n","\n","    def forward(self, x, ex_features=None):\n","        return self.cnn(x)\n","\n","\n","def calc_next_len_conv1d(current_len=112500, kernel_size=16, stride=8, padding=0, dilation=1):\n","    return int(np.floor((current_len + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1))\n","\n","\n","model = arrhythmia_classifier().to(device).double()\n","lr = 0.0003\n","num_of_iteration = len(train_dataset) // batch_size\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-6)\n","criterion = nn.NLLLoss()\n","\n","\n","def train(epoch):\n","    model.train()\n","    train_loss = 0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                       100. * batch_idx / len(train_loader),\n","                       loss.item() / len(data)))\n","\n","    print('====> Epoch: {} Average loss: {:.4f}'.format(\n","        epoch, train_loss / len(train_loader.dataset)))\n","\n","\n","def test(epoch):\n","    model.eval()\n","    test_loss = 0\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(test_loader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            test_loss += loss.item()\n","\n","            if batch_idx == 0:\n","                n = min(data.size(0), 4)\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('====> Test set loss: {:.5f}'.format(test_loss))\n","    print(f'Learning rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n","\n","\n","if __name__ == \"__main__\":\n","    for epoch in range(1, num_epochs + 1):\n","        train(epoch)\n","        test(epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQc5aiZfdGwI"},"source":["torch.save(model,f\"/content/drive/MyDrive/meeting_ECG/save_model/temp.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dr8pFwc3dRcU"},"source":["num_labels_dict = {\n","    'Normal beat': 283,  # N\n","    'Left bundle branch block beat': 103,  # L\n","    'Atrial premature beat': 66,  # A\n","    'Atrial flutter': 20,  # (AFL (aux)\n","    'Atrial fibrillation': 135,  # (AFIB (aux)\n","    'Pre-excitation (WPW)': 21,  # (PREX (aux)\n","    'Premature ventricular contraction': 133,  # V\n","    'Ventricular bigeminy': 55,  # (B (aux)\n","    'Ventricular trigeminy': 13,  # (T (aux)\n","    'Ventricular tachycardia': 10,  # (VT (aux)\n","    'Idioventricular rhythm': 10,  # (IVR (aux)\n","    'Ventricular flutter': 10,  # (VFL (aux)\n","    'Fusion of ventricular and normal beat': 11,  # F\n","    'Second-degree heart block': 10,  # SHB\n","    'Pacemaker rhythm': 45,  # P\n","    'Supraventricular tachyarrhythmia': 13,  # (SVTA (aux)\n","    'Right bundle branch block beat': 62,  # R\n","}\n","num_labels_we_have = {\n","    'N': 283,  # 'Normal beat'\n","    'L': 103,  # 'Left bundle branch block beat'\n","    'A': 66,  # 'Atrial premature beat':\n","    # 'V': 133, # 'Premature ventricular contraction'\n","    # 'SHB': 10,  # 'Second-degree heart block'\n","    # 'F': 11,  # 'Fusion of ventricular and normal beat'\n","    'R': 62,  # 'Right bundle branch block beat'\n","    'AFL': 20,  # 'Atrial flutter'\n","    'AFIB': 135,  # 'Atrial fibrillation'\n","    'PREX': 21,  # 'Pre-excitation (WPW)'\n","    'B': 55,  # 'Ventricular bigeminy'\n","    'T': 13,  # 'Ventricular trigeminy'\n","    # '(VT'   : 10,  # 'Ventricular tachycardia'\n","    'IVR': 10,  # 'Idioventricular rhythm'\n","    'VFL': 10,  # 'Ventricular flutter'\n","    'P': 45  # 'Pacemaker rhythm'\n","    # '(SVTA' : 13  # 'Supraventricular tachyarrhythmia'\n","}\n","dict_mapping={\n","    'Normal beat': 'N',\n","    'Left bundle branch block beat': 'L',\n","    'Atrial premature beat': 'A',\n","    'Atrial flutter': 'AFL',\n","    'Atrial fibrillation': 'AFIB',\n","    'Pre-excitation (WPW)': 'PREX',\n","    'Premature ventricular contraction': 'V',\n","    'Ventricular bigeminy': 'B',\n","    'Ventricular trigeminy': 'T',\n","    'Ventricular tachycardia': 'VT',\n","    'Idioventricular rhythm': 'IVR',\n","    'Ventricular flutter': 'VFL',\n","    'Fusion of ventricular and normal beat': 'F',\n","    'Second-degree heart block': 'SHB',\n","    'Pacemaker rhythm': 'P',\n","    'Supraventricular tachyarrhythmia': 'SVTA',\n","    'Right bundle branch block beat': 'R',\n","}\n","label_numeric_dict = {\n","    'N': 0,\n","    'A': 1,\n","    'AFL': 2,\n","    'AFIB': 3,\n","    'PREX': 4,\n","    'B': 5,\n","    'T': 6,\n","    'IVR': 7,\n","    'VFL': 8,\n","    'L': 9,\n","    'R': 10,\n","    'P': 11\n","}\n","classes_=len(dict_mapping)\n","\n","\n","\n","\n","# model=torch.load(\"/content/drive/MyDrive/meeting_ECG/save_model/lr03_epoch8.pt\")\n","model=torch.load(\"/content/drive/MyDrive/meeting_ECG/save_model/temp.pt\")\n","\n","test_dataset = CustomDatasetFromCSV('/content/drive/MyDrive/Arrhythmia-CNN-master/data/Arrhythmia_dataset_yystest_noseed1.pkl')\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n","print(test_dataset.df)\n","\n","\n","# conf_matrix = torch.zeros(classes_,classes_)\n","dict_truth_prediction_map={}\n","count_=[0]*16\n","count_p=[0]*16\n","\n","model.eval()\n","test_loss = 0\n","with torch.no_grad():\n","    for batch_idx, (data, target) in enumerate(test_loader):\n","        data, target = data.to(device), target.to(device)\n","        output = model(data)\n","        dict_truth_prediction_map[batch_idx]=(target,output)\n","        # print(int(target))\n","        count_[int(target)]+=1\n","\n","\n","        # list_=output[0].tolist()\n","        # print(list_.index(max(list_)))\n","        # print(output[0].tolist())\n","        count_p[int(list_.index(max(list_)))]+=1\n","\n","# for idx_ in dict_truth_prediction_map:\n","#   print(idx_,'\\t',dict_truth_prediction_map[idx_])\n","\n","\n","print(count_)\n","print(count_p)"],"execution_count":null,"outputs":[]}]}